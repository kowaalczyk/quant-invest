{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from utils.data_loader import load_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AP</th>\n",
       "      <th>ARR</th>\n",
       "      <th>ARW</th>\n",
       "      <th>G</th>\n",
       "      <th>OP</th>\n",
       "      <th>ORR</th>\n",
       "      <th>ORW</th>\n",
       "      <th>a5.c</th>\n",
       "      <th>wig2</th>\n",
       "      <th>^aex</th>\n",
       "      <th>...</th>\n",
       "      <th>SEK</th>\n",
       "      <th>CHF</th>\n",
       "      <th>THB</th>\n",
       "      <th>TTD</th>\n",
       "      <th>TND</th>\n",
       "      <th>AED</th>\n",
       "      <th>GBP</th>\n",
       "      <th>USD</th>\n",
       "      <th>UYU</th>\n",
       "      <th>VEB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-03</th>\n",
       "      <td>415.90</td>\n",
       "      <td>549.11</td>\n",
       "      <td>354.45</td>\n",
       "      <td>401.26</td>\n",
       "      <td>275.08</td>\n",
       "      <td>520.13</td>\n",
       "      <td>230.72</td>\n",
       "      <td>1204.88</td>\n",
       "      <td>1852.9</td>\n",
       "      <td>675.44</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085771</td>\n",
       "      <td>0.456726</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.115867</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.197875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.726696</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-04</th>\n",
       "      <td>404.41</td>\n",
       "      <td>533.89</td>\n",
       "      <td>357.14</td>\n",
       "      <td>401.42</td>\n",
       "      <td>275.08</td>\n",
       "      <td>520.02</td>\n",
       "      <td>229.63</td>\n",
       "      <td>1194.41</td>\n",
       "      <td>1796.6</td>\n",
       "      <td>642.25</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.465253</td>\n",
       "      <td>0.019568</td>\n",
       "      <td>0.115445</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.197034</td>\n",
       "      <td>1.18701</td>\n",
       "      <td>0.723608</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-05</th>\n",
       "      <td>400.04</td>\n",
       "      <td>527.38</td>\n",
       "      <td>351.19</td>\n",
       "      <td>401.59</td>\n",
       "      <td>275.08</td>\n",
       "      <td>519.22</td>\n",
       "      <td>229.22</td>\n",
       "      <td>1192.89</td>\n",
       "      <td>1777.0</td>\n",
       "      <td>632.31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086740</td>\n",
       "      <td>0.466615</td>\n",
       "      <td>0.019422</td>\n",
       "      <td>0.115510</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.197039</td>\n",
       "      <td>1.18624</td>\n",
       "      <td>0.723627</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-06</th>\n",
       "      <td>410.15</td>\n",
       "      <td>522.02</td>\n",
       "      <td>347.96</td>\n",
       "      <td>401.75</td>\n",
       "      <td>275.07</td>\n",
       "      <td>519.62</td>\n",
       "      <td>228.82</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1832.1</td>\n",
       "      <td>624.21</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.468650</td>\n",
       "      <td>0.019427</td>\n",
       "      <td>0.115662</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.197260</td>\n",
       "      <td>1.19474</td>\n",
       "      <td>0.724439</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-07</th>\n",
       "      <td>429.16</td>\n",
       "      <td>533.16</td>\n",
       "      <td>351.87</td>\n",
       "      <td>401.93</td>\n",
       "      <td>275.07</td>\n",
       "      <td>520.80</td>\n",
       "      <td>230.09</td>\n",
       "      <td>1223.61</td>\n",
       "      <td>1933.2</td>\n",
       "      <td>644.86</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.465233</td>\n",
       "      <td>0.019410</td>\n",
       "      <td>0.115876</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.197989</td>\n",
       "      <td>1.19596</td>\n",
       "      <td>0.727113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                AP     ARR     ARW       G      OP     ORR     ORW     a5.c  \\\n",
       "2000-01-03  415.90  549.11  354.45  401.26  275.08  520.13  230.72  1204.88   \n",
       "2000-01-04  404.41  533.89  357.14  401.42  275.08  520.02  229.63  1194.41   \n",
       "2000-01-05  400.04  527.38  351.19  401.59  275.08  519.22  229.22  1192.89   \n",
       "2000-01-06  410.15  522.02  347.96  401.75  275.07  519.62  228.82      NaN   \n",
       "2000-01-07  429.16  533.16  351.87  401.93  275.07  520.80  230.09  1223.61   \n",
       "\n",
       "              wig2    ^aex  ...       SEK       CHF       THB       TTD  TND  \\\n",
       "2000-01-03  1852.9  675.44  ...  0.085771  0.456726       NaN  0.115867  NaN   \n",
       "2000-01-04  1796.6  642.25  ...       NaN  0.465253  0.019568  0.115445  NaN   \n",
       "2000-01-05  1777.0  632.31  ...  0.086740  0.466615  0.019422  0.115510  NaN   \n",
       "2000-01-06  1832.1  624.21  ...       NaN  0.468650  0.019427  0.115662  NaN   \n",
       "2000-01-07  1933.2  644.86  ...       NaN  0.465233  0.019410  0.115876  NaN   \n",
       "\n",
       "                 AED      GBP       USD  UYU       VEB  \n",
       "2000-01-03  0.197875      NaN  0.726696  NaN       NaN  \n",
       "2000-01-04  0.197034  1.18701  0.723608  NaN  0.001114  \n",
       "2000-01-05  0.197039  1.18624  0.723627  NaN  0.001114  \n",
       "2000-01-06  0.197260  1.19474  0.724439  NaN  0.001115  \n",
       "2000-01-07  0.197989  1.19596  0.727113  NaN  0.001118  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_all()\n",
    "df = df.loc[~df['AP'].isna()]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4801, 200)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "fund_colnames = ['AP', 'ARR', 'ARW', 'G', 'OP', 'ORR', 'ORW']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "funds_df = df[fund_colnames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4801, 7)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "funds_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature and target selection\n",
    "\n",
    "Firstly, we will try to train a classifier that selects the best performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_len = 2*year_days\n",
    "train_df = funds_df.iloc[:-test_set_len]\n",
    "test_df = funds_df.iloc[test_set_len:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x23b634c8390>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(BasicLSTM, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim)\n",
    "        self.fc1 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return (torch.zeros(1, 1, self.hidden_dim),\n",
    "                torch.zeros(1, 1, self.hidden_dim))\n",
    "\n",
    "    def forward(self, tensor):\n",
    "        tensor, self.hidden = self.lstm(\n",
    "            tensor.view(len(tensor), 1, -1), \n",
    "            self.hidden\n",
    "        )\n",
    "        tensor = self.fc1(tensor)\n",
    "        tensor = self.fc2(tensor)\n",
    "        tensor = torch.sigmoid(tensor)\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 100\n",
    "lr = 0.02137\n",
    "model_hidden_dim = 49\n",
    "min_seq_len = 3*year_days\n",
    "val_set_len = 2*year_days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BasicLSTM(7, model_hidden_dim, 7)\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▊                                                                               | 33/3037 [00:18<26:00,  1.92it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-69-c788fd8e88f6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;31m# forward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[1;31m# backprop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\quant-invest\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-66-900ad7931d60>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m     15\u001b[0m         tensor, self.hidden = self.lstm(\n\u001b[0;32m     16\u001b[0m             \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         )\n\u001b[0;32m     19\u001b[0m         \u001b[0mtensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\quant-invest\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\quant-invest\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m             result = _impl(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[1;32m--> 179\u001b[1;33m                            self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[0;32m    180\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m             result = _impl(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    # training\n",
    "    for target_idx in tqdm(range(min_seq_len, len(train_df)-val_set_len)):\n",
    "        sequence = torch.Tensor(train_df.iloc[:target_idx].values)\n",
    "        target = torch.Tensor(train_df.iloc[target_idx].values)\n",
    "        # reset state\n",
    "        model.zero_grad()\n",
    "        model.hidden = model.init_hidden()\n",
    "        # forward\n",
    "        pred = model(sequence)\n",
    "        # backprop\n",
    "        loss = loss_function(pred, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # validation\n",
    "    with torch.no_grad():\n",
    "        losses = torch.zeros(y_val.shape[0])\n",
    "        for i, target_idx in tqdm(enumerate(range(len(train_df)-val_set_len, len(train_df)))):\n",
    "            sequence = torch.Tensor(train_df.iloc[:target_idx].values)\n",
    "            target = torch.Tensor(train_df.iloc[target_idx].values)\n",
    "            pred = model(sequence)\n",
    "            losses[i] = loss_function(pred, target)\n",
    "        pd.Series(losses.numpy()).plot(title=f\"Epoch {epoch} validation loss\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
